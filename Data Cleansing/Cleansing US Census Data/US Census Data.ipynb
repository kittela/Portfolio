{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943f047d",
   "metadata": {},
   "source": [
    "# Cleansing of US Census Data\n",
    "In this project, we will be working with a series of spreadsheets obtained from the US Census Bureau.  The data will be imported from multiple spreadsheets, cleansed, and prepared for analysis and visualization using tools in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c31821",
   "metadata": {},
   "source": [
    "## Importing Libraries and Data\n",
    "First, we will import the libraries to use.  This includes Glob to assist in importing the spreadsheets, Pandas and Numpy for data organization and analysis, and Pyplot for data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "040374fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Making the default plot size larger for easier visualization\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "331f843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0           State  TotalPop Hispanic   White   Black Native  \\\n",
      "0           0    Rhode Island   1053661   13.36%  74.33%   5.68%  0.35%   \n",
      "1           1  South Carolina   4777576    5.06%  62.89%  28.75%  0.29%   \n",
      "2           2    South Dakota    843190    3.24%  82.50%   1.42%  9.42%   \n",
      "3           3       Tennessee   6499615    4.72%  73.49%  18.28%  0.23%   \n",
      "4           4           Texas  26538614   38.05%  44.69%  11.65%  0.26%   \n",
      "\n",
      "   Asian Pacific       Income            GenderPop  \n",
      "0  3.25%   0.04%  $59,125.27       510388M_543273F  \n",
      "1  1.25%   0.05%  $46,296.81     2322409M_2455167F  \n",
      "2  1.02%   0.04%  $51,805.41       423477M_419713F  \n",
      "3  1.41%   0.04%  $47,328.08     3167756M_3331859F  \n",
      "4  3.67%   0.07%  $55,874.52   13171316M_13367298F  \n",
      "Unnamed: 0     int64\n",
      "State         object\n",
      "TotalPop       int64\n",
      "Hispanic      object\n",
      "White         object\n",
      "Black         object\n",
      "Native        object\n",
      "Asian         object\n",
      "Pacific       object\n",
      "Income        object\n",
      "GenderPop     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# The data is spread across 10 CSV files.  We have moved the files to their own 'Data' folder and will use\n",
    "# glob to iterate through them and read their contents into dataframes\n",
    "\n",
    "path = 'Data'\n",
    "files = glob.glob(path + '/*.csv')\n",
    "df_list = [pd.read_csv(file) for file in files]\n",
    "\n",
    "# Now combining the individual dataframes into one\n",
    "\n",
    "df = pd.concat(df_list, axis = 0)\n",
    "\n",
    "# And inspecting the first few rows and data types\n",
    "\n",
    "print(df.head())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f494ea",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "From the initial inspection of our imported data, the first things we may notice is that it is out of order and has a column named 'Unnamed: 0' which appears to be a duplicate of the indices.  We will address this by sorting on the 'State' column, removing the 'Unnamed: 0' column, and resetting the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bafbd3a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State  TotalPop Hispanic   White   Black  Native   Asian Pacific  \\\n",
      "0     Alabama   4830620    3.75%  61.88%  31.25%   0.45%   1.05%   0.03%   \n",
      "1      Alaska    733375    5.91%  60.91%   2.85%  16.39%   5.45%   1.06%   \n",
      "2     Arizona   6641928   29.57%  57.12%   3.85%   4.36%   2.88%   0.17%   \n",
      "3    Arkansas   2958208    6.22%  71.14%  18.97%   0.52%   1.14%   0.15%   \n",
      "4  California  38421464   37.29%  40.22%   5.68%   0.41%  13.05%   0.35%   \n",
      "\n",
      "        Income            GenderPop  \n",
      "0  $43,296.36     2341093M_2489527F  \n",
      "1  $70,354.74       384160M_349215F  \n",
      "2  $54,207.82     3299088M_3342840F  \n",
      "3  $41,935.63     1451913M_1506295F  \n",
      "4  $67,264.78   19087135M_19334329F  \n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(by = 'State').drop(['Unnamed: 0'], axis = 1).reset_index(drop = True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23846211",
   "metadata": {},
   "source": [
    "Now we can look at cleaning the values themselves.  We'll want to perform analyses on the data which would currently be prevented by the special characters such as dollar signs and percentages.  Our next step will be to remove these special characters and then convert the columns to numerics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1953f57f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State         object\n",
      "TotalPop       int64\n",
      "Hispanic     float64\n",
      "White        float64\n",
      "Black        float64\n",
      "Native       float64\n",
      "Asian        float64\n",
      "Pacific      float64\n",
      "Income       float64\n",
      "GenderPop     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Removing all commas, dollar signs, and percent signs using regex.\n",
    "\n",
    "df.replace('[$%,]', '', regex = True, inplace = True)\n",
    "\n",
    "# Converting relevant columns to numeric.\n",
    "\n",
    "df[['Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific', 'Income']] = \\\n",
    "    df[['Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific', 'Income']].apply(pd.to_numeric)\n",
    "\n",
    "# Converting percentages to their decimal format\n",
    "\n",
    "df[['Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific']] = \\\n",
    "    round(df[['Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific']] / 100, 4)\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020dd2ca",
   "metadata": {},
   "source": [
    "One messy column remains which is 'GenderPop'.  We can see from our earlier inspection that this column contains counts of a state's population by gender combined into a single string.  To make this information useful, we'll split it into two additional columns: 'Male' and 'Female'.  These columns will contain the percentage of males and females making up the population of the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5913aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we remove the 'M' and 'F' indicators and split the column on the underscore.\n",
    "\n",
    "mf_count = list(df.GenderPop.replace('[MF]', '', regex = True).str.split('_'))\n",
    "\n",
    "# Then we create the new columns using list comprehension\n",
    "\n",
    "df['Male'] = [i[0] for i in mf_count]\n",
    "df['Female'] = [i[1] for i in mf_count]\n",
    "\n",
    "# We can now easily convert the columns to their percentages\n",
    "\n",
    "df.Male = round(pd.to_numeric(df.Male) / df.TotalPop, 4)\n",
    "df.Female = round(pd.to_numeric(df.Female) / df.TotalPop, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01964cd0",
   "metadata": {},
   "source": [
    "During this process, we may have noticed that there are several missing (NaN) values in the 'Female' column.  Since we still have the total population and the proportion of males, we can infer the values and fill in the missing fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f243700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Female = df.Female.fillna(1 - df.Male)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff6303",
   "metadata": {},
   "source": [
    "Now that our data is clean there is another issue we'll want to address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01c8f7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b4a39",
   "metadata": {},
   "source": [
    "We have 60 rows in our data - it would appear we have duplicates.  We can remedy that very simply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ee9b9af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 12)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates().reset_index(drop = True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64e3ace",
   "metadata": {},
   "source": [
    "Our data is now clean enough for analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a1fd05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Pacific</th>\n",
       "      <th>Income</th>\n",
       "      <th>GenderPop</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>4830620</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>43296.36</td>\n",
       "      <td>2341093M_2489527F</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.5154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>733375</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.1639</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>70354.74</td>\n",
       "      <td>384160M_349215F</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.4762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>6641928</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>54207.82</td>\n",
       "      <td>3299088M_3342840F</td>\n",
       "      <td>0.4967</td>\n",
       "      <td>0.5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2958208</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.7114</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>41935.63</td>\n",
       "      <td>1451913M_1506295F</td>\n",
       "      <td>0.4908</td>\n",
       "      <td>0.5092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>38421464</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.4022</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>67264.78</td>\n",
       "      <td>19087135M_19334329F</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.5032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  TotalPop  Hispanic   White   Black  Native   Asian  Pacific  \\\n",
       "0     Alabama   4830620    0.0375  0.6188  0.3125  0.0045  0.0105   0.0003   \n",
       "1      Alaska    733375    0.0591  0.6091  0.0285  0.1639  0.0545   0.0106   \n",
       "2     Arizona   6641928    0.2957  0.5712  0.0385  0.0436  0.0288   0.0017   \n",
       "3    Arkansas   2958208    0.0622  0.7114  0.1897  0.0052  0.0114   0.0015   \n",
       "4  California  38421464    0.3729  0.4022  0.0568  0.0041  0.1305   0.0035   \n",
       "\n",
       "     Income            GenderPop    Male  Female  \n",
       "0  43296.36    2341093M_2489527F  0.4846  0.5154  \n",
       "1  70354.74      384160M_349215F  0.5238  0.4762  \n",
       "2  54207.82    3299088M_3342840F  0.4967  0.5033  \n",
       "3  41935.63    1451913M_1506295F  0.4908  0.5092  \n",
       "4  67264.78  19087135M_19334329F  0.4968  0.5032  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
